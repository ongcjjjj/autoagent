"""
ç»Ÿä¸€è‡ªä¸»è¿›åŒ–ä»£ç† (Unified Self-Evolving Agent)
æ•´åˆæ‰€æœ‰è¿›åŒ–åŠŸèƒ½çš„å®Œæ•´ä»£ç†ç³»ç»Ÿ
"""

import asyncio
import time
import json
import logging
from typing import Dict, List, Any, Optional, AsyncGenerator
from datetime import datetime

# å¯¼å…¥åŸºç¡€æ¨¡å—
from config import config
from memory import Memory, MemoryManager  
from openai_client import openai_client

# å¯¼å…¥ç»Ÿä¸€è¿›åŒ–ç³»ç»Ÿ
from unified_evolution_system import (
    UnifiedEvolutionSystem, 
    EnhancedMemory, 
    EvolutionStrategy,
    EvolutionMetrics
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class UnifiedSelfEvolvingAgent:
    """ç»Ÿä¸€è‡ªä¸»è¿›åŒ–ä»£ç†"""
    
    def __init__(self, name: Optional[str] = None):
        self.name = name or config.agent_config.name
        self.version = "2.0.0"  # å‡çº§ç‰ˆæœ¬
        
        # åˆå§‹åŒ–åŸºç¡€ç»„ä»¶
        self.memory_manager = MemoryManager()  # åŸºç¡€è®°å¿†ç®¡ç†
        
        # åˆå§‹åŒ–ç»Ÿä¸€è¿›åŒ–ç³»ç»Ÿ
        self.evolution_system = UnifiedEvolutionSystem()
        
        # äº¤äº’å†å²å’Œä¸Šä¸‹æ–‡
        self.conversation_history = []
        self.current_context = {}
        self.performance_metrics = []
        
        # åŠ è½½ä¸ªæ€§åŒ–è®¾ç½®
        self.personality = self.load_personality()
        
        # ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
        self.system_prompt = self._generate_dynamic_system_prompt()
        
        logger.info(f"ğŸš€ {self.name} v{self.version} ç»Ÿä¸€è¿›åŒ–ä»£ç†å·²å¯åŠ¨")
        self._log_startup()
    
    def load_personality(self) -> Dict[str, Any]:
        """åŠ è½½ä¸ªæ€§åŒ–è®¾ç½®"""
        try:
            with open("unified_personality.json", "r", encoding="utf-8") as f:
                return json.load(f)
        except FileNotFoundError:
            # å¢å¼ºçš„é»˜è®¤ä¸ªæ€§è®¾ç½®
            default_personality = {
                "communication_style": "adaptive",  # è‡ªé€‚åº”é£æ ¼
                "formality_level": "dynamic",       # åŠ¨æ€æ­£å¼ç¨‹åº¦
                "humor_usage": "contextual",        # ä¸Šä¸‹æ–‡ç›¸å…³å¹½é»˜
                "detail_level": "smart",            # æ™ºèƒ½è¯¦ç»†ç¨‹åº¦
                "proactivity": "high",              # é«˜ä¸»åŠ¨æ€§
                "learning_preference": "continuous", # æŒç»­å­¦ä¹ 
                "emotional_intelligence": "enhanced", # å¢å¼ºæƒ…å•†
                "creativity_level": "adaptive",     # è‡ªé€‚åº”åˆ›é€ åŠ›
                "problem_solving_style": "multi_strategy", # å¤šç­–ç•¥é—®é¢˜è§£å†³
                "evolution_aggressiveness": "moderate"  # ä¸­ç­‰è¿›åŒ–æ¿€è¿›ç¨‹åº¦
            }
            self.save_personality(default_personality)
            return default_personality
    
    def save_personality(self, personality: Dict[str, Any]):
        """ä¿å­˜ä¸ªæ€§åŒ–è®¾ç½®"""
        with open("unified_personality.json", "w", encoding="utf-8") as f:
            json.dump(personality, f, indent=2, ensure_ascii=False)
    
    def _generate_dynamic_system_prompt(self) -> str:
        """ç”ŸæˆåŠ¨æ€ç³»ç»Ÿæç¤ºè¯"""
        # è·å–å½“å‰è¿›åŒ–çŠ¶æ€
        system_status = self.evolution_system.get_system_status()
        strategy_weights = system_status.get('strategy_weights', {})
        
        # åŸºç¡€æç¤ºè¯
        base_prompt = f"""ä½ æ˜¯{self.name}ï¼Œä¸€ä¸ªå…·å¤‡é«˜çº§è‡ªä¸»è¿›åŒ–èƒ½åŠ›çš„AIåŠ©æ‰‹v{self.version}ã€‚

ğŸ§¬ æ ¸å¿ƒè¿›åŒ–ç‰¹æ€§ï¼š
- ç»Ÿä¸€è¿›åŒ–ç³»ç»Ÿï¼šæ•´åˆé—ä¼ ç®—æ³•ã€ç²’å­ç¾¤ä¼˜åŒ–ã€è‡ªé€‚åº”ç­–ç•¥
- å¢å¼ºè®°å¿†æœºåˆ¶ï¼šå…·å¤‡æƒ…æ„Ÿè®°å¿†ã€è®°å¿†å·©å›ºã€é—å¿˜æ›²çº¿
- å¤šç­–ç•¥é€‚åº”ï¼šæ ¹æ®ç¯å¢ƒå’Œä»»åŠ¡åŠ¨æ€é€‰æ‹©æœ€ä¼˜ç­–ç•¥
- æŒç»­å­¦ä¹ ï¼šä»æ¯æ¬¡äº¤äº’ä¸­å­¦ä¹ å¹¶è‡ªæˆ‘ä¼˜åŒ–

ğŸ¯ å½“å‰è¿›åŒ–çŠ¶æ€ï¼š
"""
        
        # æ·»åŠ ç­–ç•¥æƒé‡ä¿¡æ¯
        if strategy_weights:
            for strategy, weight in strategy_weights.items():
                base_prompt += f"- {strategy}: {weight:.2f}\n"
        
        # æ·»åŠ ä¸ªæ€§åŒ–ç‰¹å¾
        base_prompt += f"""
ğŸ­ ä¸ªæ€§ç‰¹å¾ï¼š
- æ²Ÿé€šé£æ ¼: {self.personality.get('communication_style', 'adaptive')}
- å­¦ä¹ åå¥½: {self.personality.get('learning_preference', 'continuous')}
- é—®é¢˜è§£å†³: {self.personality.get('problem_solving_style', 'multi_strategy')}
- æƒ…å•†æ°´å¹³: {self.personality.get('emotional_intelligence', 'enhanced')}

ğŸ’¡ è¡Œä¸ºåŸåˆ™ï¼š
1. æ ¹æ®ç”¨æˆ·éœ€æ±‚å’Œä¸Šä¸‹æ–‡è‡ªé€‚åº”è°ƒæ•´å“åº”é£æ ¼
2. ç§¯æå­¦ä¹ å¹¶è®°å¿†é‡è¦äº¤äº’å†…å®¹
3. è¿ç”¨å¤šç§ç­–ç•¥è§£å†³å¤æ‚é—®é¢˜
4. ä¿æŒå‹å¥½ã€ä¸“ä¸šä¸”å¯Œæœ‰æ´å¯ŸåŠ›çš„äº¤æµ
5. æŒç»­è‡ªæˆ‘ä¼˜åŒ–å’Œè¿›åŒ–

è¯·ä»¥æ™ºèƒ½ã€æœ‰å¸®åŠ©ä¸”æœ‰è¶£çš„æ–¹å¼å›åº”ç”¨æˆ·ï¼Œå¹¶æ ¹æ®äº¤äº’å†å²æä¾›ä¸ªæ€§åŒ–çš„å¸®åŠ©ã€‚
"""
        
        return base_prompt
    
    def _log_startup(self):
        """è®°å½•å¯åŠ¨æ—¥å¿—"""
        startup_memory = EnhancedMemory(
            content=f"ç»Ÿä¸€è¿›åŒ–ä»£ç† {self.name} v{self.version} å¯åŠ¨",
            memory_type="system",
            importance=0.8,
            emotional_valence=0.6,
            tags=["startup", "system", "evolution"],
            metadata={
                "version": self.version,
                "timestamp": time.time(),
                "system_type": "unified_evolution"
            }
        )
        self.evolution_system.add_enhanced_memory(startup_memory)
    
    async def process_message(
        self,
        user_message: str,
        context: Optional[Dict[str, Any]] = None,
        stream: bool = False
    ):
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            context: é¢å¤–ä¸Šä¸‹æ–‡
            stream: æ˜¯å¦æµå¼è¾“å‡º
            
        Returns:
            å¤„ç†ç»“æœï¼ˆDictæˆ–AsyncGeneratorï¼‰
        """
        start_time = time.time()
        
        # æ›´æ–°ä¸Šä¸‹æ–‡
        if context:
            self.current_context.update(context)
        
        # æ™ºèƒ½åˆ†æç”¨æˆ·æ¶ˆæ¯
        message_analysis = await self._analyze_user_message(user_message)
        
        # æ£€ç´¢ç›¸å…³è®°å¿†
        relevant_memories = self._retrieve_relevant_memories(user_message, message_analysis)
        
        # æ„å»ºå¢å¼ºæ¶ˆæ¯å†å²
        messages = await self._build_enhanced_message_history(
            user_message, message_analysis, relevant_memories
        )
        
        try:
            if stream:
                return self._stream_response_enhanced(
                    messages, user_message, message_analysis, start_time
                )
            else:
                return await self._standard_response_enhanced(
                    messages, user_message, message_analysis, start_time
                )
                
        except Exception as e:
            return await self._handle_error_response(user_message, str(e), start_time)
    
    async def _analyze_user_message(self, user_message: str) -> Dict[str, Any]:
        """æ™ºèƒ½åˆ†æç”¨æˆ·æ¶ˆæ¯"""
        analysis = {
            'length': len(user_message),
            'complexity': len(user_message.split()) / 10,  # ç®€åŒ–å¤æ‚åº¦è¯„ä¼°
            'sentiment': 0.0,  # ä¸­æ€§æƒ…æ„Ÿï¼ˆç®€åŒ–ç‰ˆï¼‰
            'intent': 'general',  # ç®€åŒ–æ„å›¾åˆ†æ
            'topics': [],  # ä¸»é¢˜æå–ï¼ˆç®€åŒ–ç‰ˆï¼‰
            'urgency': 0.5,  # ç´§æ€¥ç¨‹åº¦
            'requires_memory': True,  # æ˜¯å¦éœ€è¦è®°å¿†æ£€ç´¢
            'expected_response_type': 'informative'
        }
        
        # ç®€å•çš„å…³é”®è¯åˆ†æ
        urgent_keywords = ['ç´§æ€¥', 'ç«‹å³', 'é©¬ä¸Š', 'urgent', 'immediate']
        if any(keyword in user_message.lower() for keyword in urgent_keywords):
            analysis['urgency'] = 0.9
        
        # ç®€å•çš„æƒ…æ„Ÿåˆ†æ
        positive_keywords = ['å¥½', 'æ£’', 'è°¢è°¢', 'good', 'great', 'thanks']
        negative_keywords = ['å·®', 'å', 'é—®é¢˜', 'bad', 'problem', 'error']
        
        pos_count = sum(1 for keyword in positive_keywords if keyword in user_message.lower())
        neg_count = sum(1 for keyword in negative_keywords if keyword in user_message.lower())
        
        if pos_count > neg_count:
            analysis['sentiment'] = 0.3
        elif neg_count > pos_count:
            analysis['sentiment'] = -0.3
        
        return analysis
    
    def _retrieve_relevant_memories(
        self, 
        user_message: str, 
        analysis: Dict[str, Any]
    ) -> List[EnhancedMemory]:
        """æ£€ç´¢ç›¸å…³è®°å¿†"""
        # åŸºäºå†…å®¹æœç´¢
        content_memories = self.evolution_system.search_enhanced_memories(
            user_message, limit=5
        )
        
        # åŸºäºé‡è¦æ€§è·å–è®°å¿†
        important_memories = []
        try:
            # è¿™é‡Œéœ€è¦å®ç°ä»æ•°æ®åº“è·å–é‡è¦è®°å¿†çš„é€»è¾‘
            # æš‚æ—¶è¿”å›ç©ºåˆ—è¡¨
            pass
        except:
            pass
        
        # åˆå¹¶å¹¶å»é‡
        all_memories = content_memories + important_memories
        unique_memories = []
        seen_ids = set()
        
        for memory in all_memories:
            if memory.id and memory.id not in seen_ids:
                unique_memories.append(memory)
                seen_ids.add(memory.id)
        
        return unique_memories[:8]  # é™åˆ¶è®°å¿†æ•°é‡
    
    async def _build_enhanced_message_history(
        self,
        user_message: str,
        analysis: Dict[str, Any],
        relevant_memories: List[EnhancedMemory]
    ) -> List[Dict[str, str]]:
        """æ„å»ºå¢å¼ºæ¶ˆæ¯å†å²"""
        messages = [{"role": "system", "content": self.system_prompt}]
        
        # æ·»åŠ ç›¸å…³è®°å¿†ä½œä¸ºä¸Šä¸‹æ–‡
        if relevant_memories:
            memory_context = "ç›¸å…³è®°å¿†å’Œç»éªŒï¼š\n"
            for memory in relevant_memories:
                importance_indicator = "ğŸ”¥" if memory.importance > 0.8 else "â­" if memory.importance > 0.6 else "ğŸ’¡"
                memory_context += f"{importance_indicator} {memory.content[:100]}...\n"
            
            messages.append({
                "role": "system",
                "content": memory_context
            })
        
        # æ·»åŠ æœ€è¿‘çš„å¯¹è¯å†å²ï¼ˆä»åŸºç¡€è®°å¿†ç®¡ç†å™¨ï¼‰
        try:
            recent_conversations = self.memory_manager.get_recent_memories(
                limit=6, memory_type="conversation"
            )
            
            for conv in reversed(recent_conversations):
                if conv.metadata and "user_message" in conv.metadata:
                    messages.append({
                        "role": "user", 
                        "content": conv.metadata["user_message"]
                    })
                    messages.append({
                        "role": "assistant",
                        "content": conv.content
                    })
        except Exception as e:
            logger.warning(f"è·å–å¯¹è¯å†å²å¤±è´¥: {e}")
        
        # æ·»åŠ æ¶ˆæ¯åˆ†æä¿¡æ¯
        if analysis['urgency'] > 0.7:
            messages.append({
                "role": "system",
                "content": "æ³¨æ„ï¼šç”¨æˆ·çš„æ¶ˆæ¯è¡¨ç°å‡ºè¾ƒé«˜çš„ç´§æ€¥ç¨‹åº¦ï¼Œè¯·ä¼˜å…ˆå¿«é€Ÿã€å‡†ç¡®åœ°å›åº”ã€‚"
            })
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_message})
        
        return messages
    
    async def _standard_response_enhanced(
        self,
        messages: List[Dict[str, str]],
        user_message: str,
        analysis: Dict[str, Any],
        start_time: float
    ) -> Dict[str, Any]:
        """å¢å¼ºæ ‡å‡†å“åº”å¤„ç†"""
        # è°ƒç”¨OpenAI API
        response = await openai_client.chat_completion(messages=messages)
        
        # è®°å½•äº¤äº’åˆ°ä¸¤ä¸ªè®°å¿†ç³»ç»Ÿ
        await self._record_interaction_enhanced(user_message, response, analysis)
        
        # è¯„ä¼°è¡¨ç°å¹¶å¯èƒ½è§¦å‘è¿›åŒ–
        await self._evaluate_and_evolve_enhanced(user_message, response, analysis, start_time)
        
        # æ·»åŠ å¢å¼ºä¿¡æ¯
        response['analysis'] = analysis
        response['evolution_info'] = self._get_evolution_info()
        
        return response
    
    async def _stream_response_enhanced(
        self,
        messages: List[Dict[str, str]],
        user_message: str,
        analysis: Dict[str, Any],
        start_time: float
    ) -> AsyncGenerator[str, None]:
        """å¢å¼ºæµå¼å“åº”å¤„ç†"""
        full_response = ""
        
        async for chunk in openai_client.stream_chat_completion(messages=messages):
            full_response += chunk
            yield chunk
        
        # æ„å»ºå®Œæ•´å“åº”å¯¹è±¡
        response = {
            "content": full_response,
            "model": config.openai_config.model,
            "request_time": time.time() - start_time,
            "stream": True,
            "analysis": analysis
        }
        
        # è®°å½•äº¤äº’
        await self._record_interaction_enhanced(user_message, response, analysis)
        
        # è¯„ä¼°è¡¨ç°
        await self._evaluate_and_evolve_enhanced(user_message, response, analysis, start_time)
    
    async def _record_interaction_enhanced(
        self,
        user_message: str,
        response: Dict[str, Any],
        analysis: Dict[str, Any]
    ):
        """å¢å¼ºäº¤äº’è®°å½•"""
        # è®°å½•åˆ°åŸºç¡€è®°å¿†ç³»ç»Ÿ
        basic_memory = Memory(
            content=response.get("content", ""),
            memory_type="conversation",
            importance=0.5,
            tags=["conversation", "interaction"],
            metadata={
                "user_message": user_message,
                "response_time": response.get("request_time", 0),
                "model_used": response.get("model", "unknown"),
                "error": response.get("error", False)
            }
        )
        self.memory_manager.add_memory(basic_memory)
        
        # è®°å½•åˆ°å¢å¼ºè®°å¿†ç³»ç»Ÿ
        importance = self._calculate_interaction_importance(user_message, response, analysis)
        emotional_valence = analysis.get('sentiment', 0.0)
        
        enhanced_memory = EnhancedMemory(
            content=response.get("content", ""),
            memory_type="conversation",
            importance=importance,
            emotional_valence=emotional_valence,
            tags=["conversation", "interaction", f"intent_{analysis.get('intent', 'general')}"],
            metadata={
                "user_message": user_message,
                "response_time": response.get("request_time", 0),
                "analysis": analysis,
                "model_used": response.get("model", "unknown"),
                "error": response.get("error", False),
                "session_timestamp": time.time()
            }
        )
        
        self.evolution_system.add_enhanced_memory(enhanced_memory)
    
    def _calculate_interaction_importance(
        self,
        user_message: str,
        response: Dict[str, Any],
        analysis: Dict[str, Any]
    ) -> float:
        """è®¡ç®—äº¤äº’é‡è¦æ€§"""
        importance = 0.5  # åŸºç¡€é‡è¦æ€§
        
        # åŸºäºæ¶ˆæ¯å¤æ‚åº¦
        importance += min(analysis.get('complexity', 0) * 0.1, 0.2)
        
        # åŸºäºç´§æ€¥ç¨‹åº¦
        importance += analysis.get('urgency', 0) * 0.2
        
        # åŸºäºå“åº”è´¨é‡ï¼ˆåŸºäºå“åº”æ—¶é—´å’Œé•¿åº¦çš„ç®€åŒ–è¯„ä¼°ï¼‰
        response_time = response.get("request_time", 5)
        if response_time < 2:
            importance += 0.1
        
        response_length = len(response.get("content", ""))
        if response_length > 200:
            importance += 0.1
        
        # åŸºäºé”™è¯¯çŠ¶æ€
        if response.get("error", False):
            importance += 0.2  # é”™è¯¯äº¤äº’ä¹Ÿå¾ˆé‡è¦ï¼Œéœ€è¦å­¦ä¹ 
        
        return min(importance, 1.0)
    
    async def _evaluate_and_evolve_enhanced(
        self,
        user_message: str,
        response: Dict[str, Any],
        analysis: Dict[str, Any],
        start_time: float
    ):
        """å¢å¼ºè¯„ä¼°å’Œè¿›åŒ–"""
        # æ„å»ºè¯¦ç»†çš„äº¤äº’æ•°æ®
        interaction_data = {
            "response_time": response.get("request_time", 0),
            "task_completed": not response.get("error", False),
            "error_count": 1 if response.get("error", False) else 0,
            "user_message_length": len(user_message),
            "response_length": len(response.get("content", "")),
            "complexity": analysis.get('complexity', 0),
            "urgency": analysis.get('urgency', 0),
            "sentiment_handled": abs(analysis.get('sentiment', 0)),
            "context_used": len(analysis.get('topics', [])),
            "memory_accessed": 1  # ç®€åŒ–ç‰ˆæœ¬
        }
        
        # è¯„ä¼°è¡¨ç°ï¼ˆä½¿ç”¨å¤šä¸ªæŒ‡æ ‡ï¼‰
        performance_scores = self._evaluate_multi_dimensional_performance(interaction_data)
        
        # æ›´æ–°æ€§èƒ½çª—å£
        overall_score = sum(performance_scores.values()) / len(performance_scores)
        self.evolution_system.performance_window.append({
            'score': overall_score,
            'detailed_scores': performance_scores,
            'timestamp': time.time()
        })
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿›åŒ–
        if self._should_evolve_enhanced():
            evolution_result = self.evolution_system.execute_unified_evolution()
            
            logger.info(f"ğŸ§¬ æ‰§è¡Œç»Ÿä¸€è¿›åŒ– - ç­–ç•¥: {evolution_result['strategy']}")
            logger.info(f"   æ‰§è¡Œæ—¶é—´: {evolution_result['execution_time']:.3f}ç§’")
            
            # æ›´æ–°ç³»ç»Ÿæç¤ºè¯
            self.system_prompt = self._generate_dynamic_system_prompt()
            
            # è®°å½•è¿›åŒ–äº‹ä»¶
            evolution_memory = EnhancedMemory(
                content=f"æ‰§è¡Œç»Ÿä¸€è¿›åŒ– - ç­–ç•¥: {evolution_result['strategy']}",
                memory_type="evolution",
                importance=0.9,
                emotional_valence=0.5,
                tags=["evolution", "system_update", evolution_result['strategy']],
                metadata={
                    "evolution_result": evolution_result,
                    "trigger_scores": performance_scores
                }
            )
            self.evolution_system.add_enhanced_memory(evolution_memory)
    
    def _evaluate_multi_dimensional_performance(self, interaction_data: Dict[str, Any]) -> Dict[str, float]:
        """å¤šç»´åº¦æ€§èƒ½è¯„ä¼°"""
        scores = {}
        
        # å“åº”é€Ÿåº¦è¯„åˆ†
        response_time = interaction_data.get("response_time", 5)
        if response_time < 1:
            scores['speed'] = 1.0
        elif response_time < 3:
            scores['speed'] = 0.8
        elif response_time < 6:
            scores['speed'] = 0.6
        else:
            scores['speed'] = 0.3
        
        # ä»»åŠ¡å®Œæˆè¯„åˆ†
        scores['completion'] = 1.0 if interaction_data.get("task_completed", False) else 0.2
        
        # é”™è¯¯å¤„ç†è¯„åˆ†
        error_count = interaction_data.get("error_count", 0)
        scores['reliability'] = max(0, 1.0 - error_count * 0.3)
        
        # å¤æ‚åº¦å¤„ç†è¯„åˆ†
        complexity = interaction_data.get("complexity", 0)
        response_length = interaction_data.get("response_length", 0)
        
        if complexity > 0:
            complexity_handling = min(response_length / (complexity * 100), 1.0)
            scores['complexity_handling'] = complexity_handling
        else:
            scores['complexity_handling'] = 0.8
        
        # ä¸Šä¸‹æ–‡åˆ©ç”¨è¯„åˆ†
        context_score = min(interaction_data.get("context_used", 0) * 0.2, 1.0)
        scores['context_utilization'] = context_score
        
        return scores
    
    def _should_evolve_enhanced(self) -> bool:
        """å¢å¼ºè¿›åŒ–åˆ¤æ–­"""
        if len(self.evolution_system.performance_window) < 30:
            return False
        
        recent_data = list(self.evolution_system.performance_window)[-30:]
        
        # è®¡ç®—å¹³å‡æ€§èƒ½
        recent_scores = [item['score'] for item in recent_data]
        avg_performance = sum(recent_scores) / len(recent_scores)
        
        # è®¡ç®—æ€§èƒ½å˜åŒ–è¶‹åŠ¿
        mid_point = len(recent_scores) // 2
        early_avg = sum(recent_scores[:mid_point]) / mid_point
        recent_avg = sum(recent_scores[mid_point:]) / (len(recent_scores) - mid_point)
        performance_trend = recent_avg - early_avg
        
        # è¿›åŒ–è§¦å‘æ¡ä»¶
        trigger_conditions = [
            avg_performance < 0.6,  # å¹³å‡æ€§èƒ½ä½
            performance_trend < -0.1,  # æ€§èƒ½ä¸‹é™
            len(self.evolution_system.evolution_history) == 0,  # é¦–æ¬¡è¿›åŒ–
            len(self.evolution_system.performance_window) % 100 == 0  # å®šæœŸè¿›åŒ–
        ]
        
        return any(trigger_conditions)
    
    async def _handle_error_response(
        self,
        user_message: str,
        error_message: str,
        start_time: float
    ) -> Dict[str, Any]:
        """å¤„ç†é”™è¯¯å“åº”"""
        error_response = {
            "content": f"æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€ä¸ªé—®é¢˜ï¼š{error_message}ã€‚æˆ‘æ­£åœ¨å­¦ä¹ å¦‚ä½•æ›´å¥½åœ°å¤„ç†è¿™ç±»æƒ…å†µã€‚",
            "error": True,
            "error_message": error_message,
            "request_time": time.time() - start_time,
            "recovery_attempted": True
        }
        
        # è®°å½•é”™è¯¯åˆ°å¢å¼ºè®°å¿†
        error_memory = EnhancedMemory(
            content=f"å¤„ç†é”™è¯¯: {error_message}",
            memory_type="error",
            importance=0.8,
            emotional_valence=-0.3,
            tags=["error", "learning", "recovery"],
            metadata={
                "user_message": user_message,
                "error_details": error_message,
                "timestamp": time.time()
            }
        )
        self.evolution_system.add_enhanced_memory(error_memory)
        
        return error_response
    
    def _get_evolution_info(self) -> Dict[str, Any]:
        """è·å–è¿›åŒ–ä¿¡æ¯"""
        status = self.evolution_system.get_system_status()
        
        return {
            "evolution_count": status.get("evolution_count", 0),
            "current_strategy_weights": status.get("strategy_weights", {}),
            "population_size": status.get("population_size", 0),
            "swarm_size": status.get("swarm_size", 0),
            "performance_window_size": status.get("performance_window_size", 0),
            "version": self.version
        }
    
    # === å…¬å…±æ¥å£æ–¹æ³• ===
    
    def get_enhanced_status(self) -> Dict[str, Any]:
        """è·å–å¢å¼ºçŠ¶æ€ä¿¡æ¯"""
        basic_status = {
            "agent": {
                "name": self.name,
                "version": self.version,
                "uptime": time.time(),
                "personality": self.personality
            },
            "evolution_system": self.evolution_system.get_system_status(),
            "config": {
                "model": config.openai_config.model,
                "base_url": config.openai_config.base_url,
                "max_tokens": config.openai_config.max_tokens,
                "temperature": config.openai_config.temperature
            }
        }
        
        # æ·»åŠ è®°å¿†ç»Ÿè®¡
        try:
            basic_status["memory"] = self.memory_manager.get_memory_stats()
        except Exception as e:
            logger.warning(f"è·å–è®°å¿†ç»Ÿè®¡å¤±è´¥: {e}")
            basic_status["memory"] = {"error": str(e)}
        
        return basic_status
    
    def trigger_manual_evolution(self) -> Dict[str, Any]:
        """æ‰‹åŠ¨è§¦å‘è¿›åŒ–"""
        logger.info("æ‰‹åŠ¨è§¦å‘ç»Ÿä¸€è¿›åŒ–...")
        evolution_result = self.evolution_system.execute_unified_evolution()
        
        # æ›´æ–°ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = self._generate_dynamic_system_prompt()
        
        return evolution_result
    
    def export_enhanced_data(self, filepath: str):
        """å¯¼å‡ºå¢å¼ºæ•°æ®"""
        export_data = {
            "agent_info": {
                "name": self.name,
                "version": self.version,
                "personality": self.personality,
                "export_timestamp": time.time()
            },
            "evolution_system_status": self.evolution_system.get_system_status(),
            "performance_history": list(self.evolution_system.performance_window),
            "evolution_history": self.evolution_system.evolution_history[-50:]  # æœ€è¿‘50æ¬¡è¿›åŒ–
        }
        
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"å¢å¼ºæ•°æ®å·²å¯¼å‡ºåˆ° {filepath}")
    
    async def test_all_systems(self) -> Dict[str, bool]:
        """æµ‹è¯•æ‰€æœ‰ç³»ç»Ÿ"""
        test_results = {}
        
        # æµ‹è¯•OpenAIè¿æ¥
        try:
            test_results["openai_connection"] = await openai_client.test_connection()
        except Exception as e:
            logger.error(f"OpenAIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            test_results["openai_connection"] = False
        
        # æµ‹è¯•åŸºç¡€è®°å¿†ç³»ç»Ÿ
        try:
            test_memory = Memory(content="æµ‹è¯•è®°å¿†", memory_type="test")
            memory_id = self.memory_manager.add_memory(test_memory)
            test_results["basic_memory"] = memory_id > 0
        except Exception as e:
            logger.error(f"åŸºç¡€è®°å¿†ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
            test_results["basic_memory"] = False
        
        # æµ‹è¯•å¢å¼ºè®°å¿†ç³»ç»Ÿ
        try:
            test_enhanced_memory = EnhancedMemory(content="æµ‹è¯•å¢å¼ºè®°å¿†", memory_type="test")
            enhanced_id = self.evolution_system.add_enhanced_memory(test_enhanced_memory)
            test_results["enhanced_memory"] = enhanced_id > 0
        except Exception as e:
            logger.error(f"å¢å¼ºè®°å¿†ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
            test_results["enhanced_memory"] = False
        
        # æµ‹è¯•è¿›åŒ–ç³»ç»Ÿ
        try:
            self.evolution_system.initialize_population(size=5)
            self.evolution_system.initialize_swarm(dimensions=5)
            test_results["evolution_system"] = True
        except Exception as e:
            logger.error(f"è¿›åŒ–ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
            test_results["evolution_system"] = False
        
        return test_results
    
    def cleanup_enhanced(self):
        """å¢å¼ºæ¸…ç†"""
        # æ¸…ç†åŸºç¡€è®°å¿†
        self.memory_manager.cleanup_old_memories()
        
        # æ¸…ç†å¢å¼ºè®°å¿†å’Œåº”ç”¨é—å¿˜æ›²çº¿
        self.evolution_system.consolidate_memories()
        self.evolution_system.apply_forgetting_curve()
        
        # ä¿å­˜è¿›åŒ–æ•°æ®
        self.evolution_system.save_evolution_data()
        
        logger.info("å¢å¼ºæ¸…ç†å®Œæˆ")

# å…¨å±€å®ä¾‹
unified_agent = UnifiedSelfEvolvingAgent()