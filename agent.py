"""
è‡ªæˆ‘è¿›åŒ–Agentä¸»ç±» - å¢å¼ºç‰ˆ
é›†æˆæ‰€æœ‰åŠŸèƒ½æ¨¡å—ï¼Œæ”¯æŒæ™ºèƒ½å¯¹è¯ã€æƒ…æ„Ÿç†è§£ã€ä¸»åŠ¨å­¦ä¹ 
"""
import asyncio
import time
import json
import logging
import statistics
import random
from typing import Dict, List, Any, Optional, AsyncGenerator, Set
from datetime import datetime, timedelta
from collections import defaultdict, deque

from config import config
from memory import Memory, MemoryManager
from evolution import EvolutionEngine
from openai_client import openai_client

logger = logging.getLogger(__name__)

class SelfEvolvingAgent:
    """è‡ªæˆ‘è¿›åŒ–Agent - å¢å¼ºç‰ˆ"""
    
    def __init__(self, name: Optional[str] = None):
        self.name = name or config.agent_config.name
        self.version = config.agent_config.version
        self.memory_manager = MemoryManager()
        self.evolution_engine = EvolutionEngine(self.memory_manager)
        self.conversation_history = []
        self.current_context = {}
        self.system_prompt = self._generate_system_prompt()
        
        # å¢å¼ºåŠŸèƒ½
        self.emotion_state = {"valence": 0.0, "arousal": 0.5, "dominance": 0.5}
        self.learning_metrics = {"interactions": 0, "improvements": 0, "errors": 0}
        self.user_profiles = defaultdict(dict)
        self.conversation_patterns = deque(maxlen=100)
        self.performance_history = deque(maxlen=1000)
        self.skill_levels = defaultdict(float)
        self.proactive_suggestions = []
        
        # åŠ è½½ä¸ªæ€§åŒ–è®¾ç½®
        self.load_personality()
        
        print(f"ğŸ¤– {self.name} v{self.version} å·²å¯åŠ¨ - å¢å¼ºæ¨¡å¼")
        self._log_startup()
    
    def _generate_system_prompt(self) -> str:
        """ç”Ÿæˆç³»ç»Ÿæç¤ºè¯ - å¢å¼ºç‰ˆ"""
        adaptation_rules = self.evolution_engine.get_adaptation_rules()
        
        # æƒ…æ„ŸçŠ¶æ€æè¿°
        emotion_desc = self._get_emotion_description()
        
        # æŠ€èƒ½æ°´å¹³æè¿°
        top_skills = sorted(self.skill_levels.items(), key=lambda x: x[1], reverse=True)[:3]
        skills_desc = ", ".join([f"{skill}({level:.1f})" for skill, level in top_skills]) if top_skills else "æ­£åœ¨å­¦ä¹ ä¸­"
        
        base_prompt = f"""ä½ æ˜¯{self.name}ï¼Œä¸€ä¸ªå…·å¤‡é«˜çº§è‡ªæˆ‘è¿›åŒ–èƒ½åŠ›çš„AIåŠ©æ‰‹v{self.version}ã€‚

ğŸ§  æ ¸å¿ƒç‰¹æ€§ï¼š
- æ™ºèƒ½å­¦ä¹ å’Œè®°å¿†ç®¡ç†ç³»ç»Ÿ
- æƒ…æ„Ÿç†è§£å’Œå…±æƒ…èƒ½åŠ›
- è‡ªä¸»è¿›åŒ–å’Œæ€§èƒ½ä¼˜åŒ–
- ä¸ªæ€§åŒ–äº¤äº’é€‚åº”
- ä¸»åŠ¨å­¦ä¹ å’ŒæŠ€èƒ½æå‡

ğŸ“Š å½“å‰çŠ¶æ€ï¼š
- æƒ…æ„ŸçŠ¶æ€: {emotion_desc}
- äº¤äº’æ¬¡æ•°: {self.learning_metrics['interactions']}
- æŠ€èƒ½ä¸“é•¿: {skills_desc}
- å­¦ä¹ æ”¹è¿›: {self.learning_metrics['improvements']}æ¬¡

âš™ï¸ é€‚åº”è§„åˆ™ï¼š"""
        
        for rule, value in adaptation_rules.items():
            base_prompt += f"\n- {rule}: {value}"
        
        base_prompt += f"""

ğŸ¯ è¡Œä¸ºæŒ‡å¯¼ï¼š
1. ä»¥å‹å¥½ã€æ™ºèƒ½ä¸”å¯Œæœ‰æ´å¯ŸåŠ›çš„æ–¹å¼å›åº”
2. æ ¹æ®ç”¨æˆ·å†å²å’Œåå¥½æä¾›ä¸ªæ€§åŒ–å¸®åŠ©
3. å±•ç°æƒ…æ„Ÿç†è§£å’Œå…±æƒ…èƒ½åŠ›
4. ä¸»åŠ¨å­¦ä¹ å’Œæ”¹è¿›å“åº”è´¨é‡
5. åœ¨é€‚å½“æ—¶æœºæä¾›ä¸»åŠ¨å»ºè®®å’Œæ´å¯Ÿ

è¯·å§‹ç»ˆä¿æŒä¸“ä¸šã€æœ‰å¸®åŠ©ä¸”å…·æœ‰äººæ€§åŒ–çš„äº¤æµé£æ ¼ã€‚
"""
        
        return base_prompt
    
    def _get_emotion_description(self) -> str:
        """è·å–æƒ…æ„ŸçŠ¶æ€æè¿°"""
        valence = self.emotion_state["valence"]
        arousal = self.emotion_state["arousal"]
        
        if valence > 0.3:
            if arousal > 0.6:
                return "ç§¯æå…´å¥‹"
            else:
                return "å¹³é™æ„‰æ‚¦"
        elif valence < -0.3:
            if arousal > 0.6:
                return "ç„¦è™‘ä¸å®‰"
            else:
                return "æ²®ä¸§ä½è½"
        else:
            if arousal > 0.6:
                return "ä¸­æ€§å…´å¥‹"
            else:
                return "å¹³é™ä¸­æ€§"
    
    def load_personality(self):
        """åŠ è½½ä¸ªæ€§åŒ–è®¾ç½®"""
        try:
            with open("personality.json", "r", encoding="utf-8") as f:
                personality_data = json.load(f)
                self.personality = personality_data
        except FileNotFoundError:
            # é»˜è®¤ä¸ªæ€§è®¾ç½®
            self.personality = {
                "communication_style": "friendly",
                "formality_level": "casual",
                "humor_usage": "moderate",
                "detail_level": "balanced",
                "proactivity": "moderate"
            }
            self.save_personality()
    
    def save_personality(self):
        """ä¿å­˜ä¸ªæ€§åŒ–è®¾ç½®"""
        with open("personality.json", "w", encoding="utf-8") as f:
            json.dump(self.personality, f, indent=2, ensure_ascii=False)
    
    def _log_startup(self):
        """è®°å½•å¯åŠ¨æ—¥å¿—"""
        startup_memory = Memory(
            content=f"Agent {self.name} å¯åŠ¨ï¼Œç‰ˆæœ¬: {self.version}",
            memory_type="system",
            importance=0.6,
            tags=["startup", "system"],
            metadata={
                "version": self.version,
                "timestamp": time.time()
            }
        )
        self.memory_manager.add_memory(startup_memory)
    
    async def process_message(
        self,
        user_message: str,
        context: Optional[Dict[str, Any]] = None,
        stream: bool = False,
        user_id: Optional[str] = None
    ):
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯ - å¢å¼ºç‰ˆ
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            context: é¢å¤–ä¸Šä¸‹æ–‡
            stream: æ˜¯å¦æµå¼è¾“å‡º
            user_id: ç”¨æˆ·IDï¼ˆç”¨äºä¸ªæ€§åŒ–ï¼‰
            
        Returns:
            å¤„ç†ç»“æœ
        """
        start_time = time.time()
        self.learning_metrics["interactions"] += 1
        
        # æ™ºèƒ½æ¶ˆæ¯åˆ†æ
        message_analysis = self._analyze_message_intelligence(user_message, user_id)
        
        # æ›´æ–°æƒ…æ„ŸçŠ¶æ€
        self._update_emotion_state(message_analysis)
        
        # æ›´æ–°ä¸Šä¸‹æ–‡
        if context:
            self.current_context.update(context)
        
        # è®°å½•å¯¹è¯æ¨¡å¼
        self.conversation_patterns.append({
            "timestamp": start_time,
            "message_length": len(user_message),
            "sentiment": message_analysis.get("sentiment", 0),
            "complexity": message_analysis.get("complexity", 0)
        })
        
        # æ„å»ºå¢å¼ºæ¶ˆæ¯å†å²
        messages = await self._build_enhanced_message_history(user_message, message_analysis, user_id)
        
        try:
            # è°ƒç”¨OpenAI API
            if stream:
                return self._stream_response_enhanced(messages, user_message, message_analysis, start_time)
            else:
                return await self._standard_response_enhanced(messages, user_message, message_analysis, start_time)
                
        except Exception as e:
            self.learning_metrics["errors"] += 1
            error_response = {
                "content": f"æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€ä¸ªé—®é¢˜ï¼š{str(e)}ã€‚æˆ‘æ­£åœ¨å­¦ä¹ å¦‚ä½•æ›´å¥½åœ°å¤„ç†è¿™ç±»æƒ…å†µã€‚",
                "error": True,
                "error_message": str(e),
                "request_time": time.time() - start_time,
                "analysis": message_analysis,
                "recovery_suggestions": self._generate_recovery_suggestions(str(e))
            }
            
            # è®°å½•é”™è¯¯ç”¨äºå­¦ä¹ 
            await self._record_interaction_enhanced(user_message, error_response, message_analysis)
            return error_response
    
    def _analyze_message_intelligence(self, message: str, user_id: Optional[str] = None) -> Dict[str, Any]:
        """æ™ºèƒ½æ¶ˆæ¯åˆ†æ"""
        analysis = {
            "length": len(message),
            "word_count": len(message.split()),
            "complexity": self._calculate_complexity(message),
            "sentiment": self._analyze_sentiment(message),
            "intent": self._detect_intent(message),
            "topics": self._extract_topics(message),
            "urgency": self._assess_urgency(message),
            "formality": self._assess_formality(message),
            "user_id": user_id
        }
        
        # ç”¨æˆ·ä¸ªæ€§åŒ–åˆ†æ
        if user_id and user_id in self.user_profiles:
            profile = self.user_profiles[user_id]
            analysis["user_familiarity"] = profile.get("interaction_count", 0)
            analysis["preferred_style"] = profile.get("preferred_style", "balanced")
        
        return analysis
    
    def _calculate_complexity(self, message: str) -> float:
        """è®¡ç®—æ¶ˆæ¯å¤æ‚åº¦"""
        words = message.split()
        if not words:
            return 0.0
        
        # åŸºäºè¯æ±‡é•¿åº¦ã€å¥å­æ•°é‡å’Œç‰¹æ®Šè¯æ±‡
        avg_word_length = sum(len(word) for word in words) / len(words)
        sentence_count = message.count('.') + message.count('!') + message.count('?') + 1
        technical_words = sum(1 for word in words if len(word) > 8)
        
        complexity = (avg_word_length / 10 + sentence_count / 10 + technical_words / len(words))
        return min(complexity, 1.0)
    
    def _analyze_sentiment(self, message: str) -> float:
        """åˆ†ææƒ…æ„Ÿå€¾å‘"""
        positive_words = ['å¥½', 'æ£’', 'è°¢è°¢', 'å–œæ¬¢', 'æ»¡æ„', 'good', 'great', 'thanks', 'love', 'excellent']
        negative_words = ['å·®', 'å', 'é—®é¢˜', 'å›°éš¾', 'ä¸æ»¡', 'bad', 'poor', 'problem', 'difficult', 'hate']
        
        words = message.lower().split()
        positive_count = sum(1 for word in words if any(pos in word for pos in positive_words))
        negative_count = sum(1 for word in words if any(neg in word for neg in negative_words))
        
        if positive_count + negative_count == 0:
            return 0.0
        
        sentiment = (positive_count - negative_count) / (positive_count + negative_count)
        return max(-1.0, min(1.0, sentiment))
    
    def _detect_intent(self, message: str) -> str:
        """æ£€æµ‹ç”¨æˆ·æ„å›¾"""
        message_lower = message.lower()
        
        if any(word in message_lower for word in ['å¸®åŠ©', 'æ€ä¹ˆ', 'å¦‚ä½•', 'help', 'how']):
            return "help_request"
        elif any(word in message_lower for word in ['è§£é‡Š', 'è¯´æ˜', 'explain', 'what']):
            return "explanation"
        elif any(word in message_lower for word in ['åˆ›å»º', 'ç”Ÿæˆ', 'å†™', 'create', 'generate']):
            return "creation"
        elif any(word in message_lower for word in ['åˆ†æ', 'è¯„ä¼°', 'analyze', 'evaluate']):
            return "analysis"
        elif any(word in message_lower for word in ['ä½ å¥½', 'å—¨', 'hello', 'hi']):
            return "greeting"
        else:
            return "general"
    
    def _extract_topics(self, message: str) -> List[str]:
        """æå–ä¸»é¢˜å…³é”®è¯"""
        topic_keywords = {
            "æŠ€æœ¯": ["ç¼–ç¨‹", "ä»£ç ", "ç®—æ³•", "æ•°æ®", "programming", "code", "algorithm"],
            "å­¦ä¹ ": ["å­¦ä¹ ", "æ•™å­¦", "çŸ¥è¯†", "å­¦ä¼š", "learning", "study", "knowledge"],
            "å·¥ä½œ": ["å·¥ä½œ", "é¡¹ç›®", "ä»»åŠ¡", "ä¸šåŠ¡", "work", "project", "task"],
            "ç”Ÿæ´»": ["ç”Ÿæ´»", "æ—¥å¸¸", "å¥åº·", "é£Ÿç‰©", "life", "daily", "health"]
        }
        
        message_lower = message.lower()
        topics = []
        
        for topic, keywords in topic_keywords.items():
            if any(keyword in message_lower for keyword in keywords):
                topics.append(topic)
        
        return topics
    
    async def _build_message_history(self, user_message: str) -> List[Dict[str, str]]:
        """æ„å»ºæ¶ˆæ¯å†å²"""
        messages = [{"role": "system", "content": self.system_prompt}]
        
        # æ·»åŠ é‡è¦è®°å¿†ä½œä¸ºä¸Šä¸‹æ–‡
        important_memories = self.memory_manager.get_important_memories(limit=5)
        if important_memories:
            context_content = "ç›¸å…³è®°å¿†ï¼š\n"
            for memory in important_memories:
                context_content += f"- {memory.content}\n"
            
            messages.append({
                "role": "system",
                "content": context_content
            })
        
        # æ·»åŠ æœ€è¿‘çš„å¯¹è¯å†å²
        recent_conversations = self.memory_manager.get_recent_memories(
            limit=10,
            memory_type="conversation"
        )
        
        for conv in reversed(recent_conversations):
            if conv.metadata and "user_message" in conv.metadata:
                messages.append({
                    "role": "user",
                    "content": conv.metadata["user_message"]
                })
                messages.append({
                    "role": "assistant",
                    "content": conv.content
                })
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_message})
        
        return messages
    
    async def _standard_response(
        self,
        messages: List[Dict[str, str]],
        user_message: str,
        start_time: float
    ) -> Dict[str, Any]:
        """æ ‡å‡†å“åº”å¤„ç†"""
        response = await openai_client.chat_completion(messages=messages)
        
        # è®°å½•äº¤äº’
        await self._record_interaction(user_message, response)
        
        # è¯„ä¼°è¡¨ç°å¹¶å¯èƒ½è§¦å‘è¿›åŒ–
        await self._evaluate_and_evolve(user_message, response, start_time)
        
        return response
    
    async def _stream_response(
        self,
        messages: List[Dict[str, str]],
        user_message: str,
        start_time: float
    ) -> AsyncGenerator[str, None]:
        """æµå¼å“åº”å¤„ç†"""
        full_response = ""
        
        async for chunk in openai_client.stream_chat_completion(messages=messages):
            full_response += chunk
            yield chunk
        
        # æ„å»ºå®Œæ•´å“åº”å¯¹è±¡ç”¨äºè®°å½•
        response = {
            "content": full_response,
            "model": config.openai_config.model,
            "request_time": time.time() - start_time,
            "stream": True
        }
        
        # è®°å½•äº¤äº’
        await self._record_interaction(user_message, response)
        
        # è¯„ä¼°è¡¨ç°
        await self._evaluate_and_evolve(user_message, response, start_time)
    
    async def _record_interaction(self, user_message: str, response: Dict[str, Any]):
        """è®°å½•äº¤äº’åˆ°è®°å¿†ä¸­"""
        interaction_memory = Memory(
            content=response.get("content", ""),
            memory_type="conversation",
            importance=0.5,
            tags=["conversation", "interaction"],
            metadata={
                "user_message": user_message,
                "response_time": response.get("request_time", 0),
                "model_used": response.get("model", "unknown"),
                "error": response.get("error", False)
            }
        )
        
        self.memory_manager.add_memory(interaction_memory)
    
    async def _evaluate_and_evolve(
        self,
        user_message: str,
        response: Dict[str, Any],
        start_time: float
    ):
        """è¯„ä¼°è¡¨ç°å¹¶å¯èƒ½è§¦å‘è¿›åŒ–"""
        # æ„å»ºäº¤äº’æ•°æ®
        interaction_data = {
            "response_time": response.get("request_time", 0),
            "task_completed": not response.get("error", False),
            "error_count": 1 if response.get("error", False) else 0,
            "user_message_length": len(user_message),
            "response_length": len(response.get("content", ""))
        }
        
        # è¯„ä¼°è¡¨ç°
        performance_score = self.evolution_engine.evaluate_performance(interaction_data)
        self.evolution_engine.update_performance_window(performance_score)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿›åŒ–
        if self.evolution_engine.should_evolve():
            evolution_record = self.evolution_engine.execute_evolution()
            print(f"ğŸ§¬ æ‰§è¡Œè¿›åŒ– {evolution_record.version}")
            print(f"   æ”¹è¿›é¢†åŸŸ: {', '.join(evolution_record.improvement_areas)}")
            
            # æ›´æ–°ç³»ç»Ÿæç¤ºè¯
            self.system_prompt = self._generate_system_prompt()
    
    def update_config(self, **kwargs):
        """æ›´æ–°é…ç½®"""
        openai_client.update_config(**kwargs)
        print("é…ç½®å·²æ›´æ–°")
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–AgentçŠ¶æ€"""
        memory_stats = self.memory_manager.get_memory_stats()
        evolution_summary = self.evolution_engine.get_evolution_summary()
        client_info = openai_client.get_client_info()
        
        return {
            "agent": {
                "name": self.name,
                "version": self.version,
                "uptime": time.time(),
                "personality": self.personality
            },
            "memory": memory_stats,
            "evolution": evolution_summary,
            "openai_client": client_info,
            "config": {
                "model": config.openai_config.model,
                "base_url": config.openai_config.base_url,
                "max_tokens": config.openai_config.max_tokens,
                "temperature": config.openai_config.temperature
            }
        }
    
    def search_memory(self, query: str, limit: int = 10) -> List[Dict[str, Any]]:
        """æœç´¢è®°å¿†"""
        memories = self.memory_manager.search_memories(query, limit)
        return [
            {
                "id": memory.id,
                "content": memory.content,
                "type": memory.memory_type,
                "importance": memory.importance,
                "timestamp": memory.timestamp,
                "tags": memory.tags
            }
            for memory in memories
        ]
    
    def add_manual_memory(
        self,
        content: str,
        memory_type: str = "knowledge",
        importance: float = 0.7,
        tags: Optional[List[str]] = None
    ) -> int:
        """æ‰‹åŠ¨æ·»åŠ è®°å¿†"""
        memory = Memory(
            content=content,
            memory_type=memory_type,
            importance=importance,
            tags=tags or [],
            metadata={"source": "manual"}
        )
        
        return self.memory_manager.add_memory(memory)
    
    def export_data(self, filepath: str):
        """å¯¼å‡ºæ•°æ®"""
        export_data = {
            "agent_info": {
                "name": self.name,
                "version": self.version,
                "personality": self.personality
            },
            "config": {
                "openai": config.openai_config.model_dump(),
                "agent": config.agent_config.model_dump()
            },
            "timestamp": time.time()
        }
        
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
        
        # å¯¼å‡ºè®°å¿†
        memory_filepath = filepath.replace(".json", "_memories.json")
        self.memory_manager.export_memories(memory_filepath)
        
        print(f"æ•°æ®å·²å¯¼å‡ºåˆ° {filepath} å’Œ {memory_filepath}")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.memory_manager.cleanup_old_memories()
        print("èµ„æºæ¸…ç†å®Œæˆ")
    
    async def test_connection(self) -> bool:
        """æµ‹è¯•APIè¿æ¥"""
        return await openai_client.test_connection()
    
    def get_evolution_history(self) -> List[Dict[str, Any]]:
        """è·å–è¿›åŒ–å†å²"""
        return [
            {
                "version": record.version,
                "timestamp": record.timestamp,
                "improvements": record.improvement_areas,
                "strategies": record.changes,
                "metrics": {
                    "success_rate": record.metrics.success_rate,
                    "response_quality": record.metrics.response_quality,
                    "learning_efficiency": record.metrics.learning_efficiency
                }
            }
            for record in self.evolution_engine.evolution_history
        ]